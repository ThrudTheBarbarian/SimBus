Storing samples
===============

When we run a simulation, the goal is to be able to run for a sufficient time
that we can get meaningful results from the simualtion. The worst-case for this
is probably audio output chips, which would need maybe ~1 minute's worth of
time to be simulated to be useful

So the target is 60 seconds of data being produced / stored / rendered.


Bit method:
-----------

If we use a structure like:

struct
    {
    int64_t cron;           // Timestamp of signal in ns, int64_t for maths
    uint8_t signals[12];    // 96 bits of signal value
    uint8_t valid[12];      // 96 bits of signal-valid data
    }                       // 256 bits in total = 32 bytes

... then we're limited to 96 bits of signal, mapped over the set provided
by the plugins, but we're using 32 bytes per sample, and those samples
aren't necessarily uniform in time.

Assuming a 20MHz clock, we would have 20M samples per second, so 20 * 32 * 60
MB needed for the entire 60 second period, or ~ 39 GB of RAM.

Pros: simple to understand, fairly easy to implement, doesn't take much space
Cons: could be slow, lots of bit-shifting
    

Value-change method:
--------------------
Alternatively if we just use per-signal changes,

struct
    {
    int64_t cron;           // 64 bits: Timestamp of signal-change
    int64_t val;            // 64 bits: New value, -ve is undefined
    }                       // 128 bits in total = 16 bytes

... and grouping bus-based signals such as address, data into 1 group, we
would need (for the 6502):
    
        Address [16]        1
        Data [8]            1
        /RDY                1
        /IRQ                1
        /NMI                1
        R/W                 1
        /RST                1
        clk                 1
        clkout              1
        clkout2             1
                        =>  10 signals, some of which are wider than others

So at a mythical 20MHz clock, and a ~50% rate of signals changing per clock,
we'd have:

    20 * 10 * 16 / 2 * 60 = 93GB for 1 minute's data  (actually 8.4GB @ 1.7MHz)
    
-ve values can represent the various undefined states (multiple drivers,
never-driven, ...)

Pros: simple to implement, faster since it only tracks changes and no bit-shifts
      easier to customise signal-count
Cons: more memory,


Practica:
---------

The more-typical use-case is not for audio-generation though, it's more likely
to be running for several thousand nanosecs, or maybe 1/60 second for a video
frame or something, so the numbers look more like:

bits:       20 * 32 / 60                => 11 MB
changes     20 * 10 * 16 / 2 / 60       => 27 MB



Summary:
--------

Best algorithm is one that works well for most of the time and can cope with the
outlier case. We ought to go for the value-change method, especially since the
main cost there is RAM, and this machine has 512 GB of it :)
